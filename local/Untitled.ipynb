{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('.'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from protonets.models import few_shot_statistic_pooling\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "kwargs['layer_sizes'] = [512, 512, 512, 512, 3 * 512]\n",
    "kwargs['kernel_sizes'] = [5, 5, 7, 1, 1]\n",
    "kwargs['embedding_sizes'] = [512, 200]\n",
    "kwargs['feature_dim'] = 60\n",
    "kwargs['dropout_keep_prob'] = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = few_shot_statistic_pooling.load_few_short_speech(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = 10\n",
    "n_query = 5\n",
    "n_support = 5\n",
    "max_len = 400\n",
    "mfcc_dim = 60\n",
    "batch = {}\n",
    "batch['xq_padded'] = torch.rand(n_class, n_query, max_len, mfcc_dim) # n_class * n_query * max_len * mfcc_dim\n",
    "batch['xs_padded'] = torch.rand(n_class, n_support, max_len, mfcc_dim) # n_class * n_support * max_len * mfcc_dim\n",
    "batch['xq_len'] = (torch.rand(n_class, n_query) * 200).int() # n_class * n_query \n",
    "batch['xs_len'] = (torch.rand(n_class, n_support) * 200).int() # n_class * n_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  36,   17,  196,   15,  125],\n",
       "        [  68,   30,   96,  147,  169],\n",
       "        [  38,   60,   79,   69,  157],\n",
       "        [  11,  156,  130,  184,   68],\n",
       "        [ 146,  176,  131,   97,   51],\n",
       "        [  38,   96,  114,   47,   88],\n",
       "        [ 132,   37,  124,   57,   33],\n",
       "        [  11,   11,   56,   59,  128],\n",
       "        [  62,  165,  195,  159,  105],\n",
       "        [ 168,   86,    3,   78,  147]], dtype=torch.int32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['xq_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-04 16:43:43,261 - INFO - few_shot_statistic_pooling - loss: 456.25457763671875, acc: 0.05999999865889549 \n",
      "INFO:protonets.models.few_shot_statistic_pooling:loss: 456.25457763671875, acc: 0.05999999865889549\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model.cuda()\n",
    "for attr in batch:\n",
    "    batch[attr] = batch[attr].to(device)\n",
    "loss = model.loss(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6027464\n"
     ]
    }
   ],
   "source": [
    "num_para = 0\n",
    "for parameter in model.parameters():\n",
    "    num = 1\n",
    "    for s in parameter.shape:\n",
    "        num *= s\n",
    "    num_para += num\n",
    "print(num_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Conv1d(16, 33, 5, padding=2)\n",
    "input = torch.randn(20, 16, 50)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(10, 200, 60)\n",
    "lengths = torch.rand(10)*200\n",
    "a = torch.arange(x.size(1))[None, :] < lengths[:, None].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  1,  1,  1,  1],\n",
       "         [ 1,  1,  1,  1,  1],\n",
       "         [ 1,  1,  1,  1,  1],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0]],\n",
       "\n",
       "        [[ 1,  1,  1,  1,  1],\n",
       "         [ 1,  1,  1,  1,  1],\n",
       "         [ 1,  1,  1,  1,  1],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0]],\n",
       "\n",
       "        [[ 1,  1,  1,  1,  1],\n",
       "         [ 1,  1,  1,  1,  1],\n",
       "         [ 1,  1,  1,  1,  1],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1,  1,  1,  1,  1],\n",
       "         [ 1,  1,  1,  1,  1],\n",
       "         [ 1,  1,  1,  1,  1],\n",
       "         ...,\n",
       "         [ 1,  1,  1,  1,  1],\n",
       "         [ 1,  1,  1,  1,  1],\n",
       "         [ 1,  1,  1,  1,  1]],\n",
       "\n",
       "        [[ 1,  1,  1,  1,  1],\n",
       "         [ 1,  1,  1,  1,  1],\n",
       "         [ 1,  1,  1,  1,  1],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0]],\n",
       "\n",
       "        [[ 1,  1,  1,  1,  1],\n",
       "         [ 1,  1,  1,  1,  1],\n",
       "         [ 1,  1,  1,  1,  1],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:, :, None].expand(*a.shape, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
